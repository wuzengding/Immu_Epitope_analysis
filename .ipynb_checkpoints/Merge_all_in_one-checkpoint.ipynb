{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708f6436-58a8-43a7-a5ac-0802fef34f95",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9af32c5-609b-43fa-84e9-227a1e036247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fded304-7e4d-4a0f-8a7f-4a8c414a6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config the path where multiple files contained.\n",
    "## NEED modify every time it runs !!!\n",
    "\n",
    "path = \"/home/jovyan/work/02.ResDev/13.Immuo_Reg_Target_epitope_mouse/mouse_2023-06-05-15\"\n",
    "homobed_or_blasp = \"homoblastp\"\n",
    "'''\n",
    "select list is \"homobed\",\"homoblastp\",\"bedblastp\"\n",
    "\"homobed\" means homobed file as input only\n",
    "\"homoblastp\" means homoblastp file as input only\n",
    "\"bedblastp\" means homobed and homoblastp files both as input\n",
    "'''\n",
    "identity = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f26d716-39c6-4155-b854-ddd8315f399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config input files under the given path.\n",
    "## No NEED modify every time it runs !!!\n",
    "\n",
    "path_mhcI = path + \"/02.protein_antigen_prediction/parsed_res_MHCI\"\n",
    "path_mhcII = path + \"/02.protein_antigen_prediction/parsed_res_MHCII\"\n",
    "APres_FIONA = path + \"/02.protein_antigen_prediction/peptide.antigen_presentation.seq2\"\n",
    "trans_memb = path + \"/04.TransMembrane.DeepTMHMM/TransMembrane.bed\"\n",
    "enzymedigest = path + \"/05.EnzymeDigest/protein.merge.enzymedigest\"\n",
    "\n",
    "if homobed_or_blasp==\"homobed\":\n",
    "    homo_bed = path + \"/03.homologous/homo_peptide.bed\"\n",
    "elif homobed_or_blasp== \"homoblastp\":\n",
    "    homo_blastp = path + \"/03.homologous/peptide_netMHC.blastp\"\n",
    "elif homobed_or_blasp== \"bedblastp\":\n",
    "    homo_bed = path + \"/03.homologous/homo_peptide.bed\"\n",
    "    homo_blastp = path + \"/03.homologous/peptide_netMHC.blastp\"\n",
    "\n",
    "outpath = path + \"/06.Deliverables/EpitopePresent\"\n",
    "outpath1 = path + \"/06.Deliverables/EpitopePresent/MHCI\"\n",
    "outpath2 = path + \"/06.Deliverables/EpitopePresent/MHCII\"\n",
    "try:\n",
    "    os.mkdir(outpath)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(outpath1)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(outpath2)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261617f8-8d47-40d4-9614-2ab7215de8df",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cc1f2d-ecbb-4d7f-a4d8-a017f64dc1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 'GGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTC')\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "def get_overlap(s1, s2):\n",
    "    s = difflib.SequenceMatcher(None, s1, s2)\n",
    "    pos_a, pos_b, size = s.find_longest_match(0, len(s1), 0, len(s2)) \n",
    "    return(size,s1[pos_a:pos_a+size])\n",
    "s1 = \"CGATTCCAGGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTC\"\n",
    "s2 = \"GGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTCGTCCAGACCCCTAGC\"\n",
    "\n",
    "print(get_overlap(s1, s2)) # GGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6a9f2c-4e12-4e74-93f6-c7367f0af142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homodict_bed(Homo_parsDict,seqid,pos1,pos2):\n",
    "    checklist = [homo_f==0 for homo_f in Homo_parsDict[seqid][pos1:pos2]]\n",
    "    if  sum(checklist)/(pos2-pos1) >= 0.05:\n",
    "        HomoEx = \"N\"\n",
    "        Homo_flag = \"\"\n",
    "    else:\n",
    "        HomoEx = \"Y\"\n",
    "        flagtemp_list = []\n",
    "        for flag in Homo_parsDict[seqid][pos1:pos2]:\n",
    "            if flag !=0:\n",
    "                flagtemp_list += flag\n",
    "        Homo_flag = \";\".join(list(dict.fromkeys(flagtemp_list)))\n",
    "    return(HomoEx,Homo_flag)\n",
    "\n",
    "def get_homodict_blastp(Homoblastp_parsDict,seqid,peptide):\n",
    "    try:\n",
    "        homolist = Homoblastp_parsDict[seqid][peptide]\n",
    "        if len(homolist) == 0:\n",
    "            Homo_flag = \"\"\n",
    "            HomoEx = \"N\"\n",
    "        else:\n",
    "            Homo_flag = ';'.join(homolist)\n",
    "            HomoEx = \"Y\"\n",
    "    except:\n",
    "        Homo_flag = \"\"\n",
    "        HomoEx = \"N\"\n",
    "    return(HomoEx,Homo_flag)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7a83e-3d7c-4ea0-998c-02b336d0bd22",
   "metadata": {},
   "source": [
    "## Step1: Parser the TransMemb.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd475435-2a50-41ad-8d2b-077906ba6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser the TransMemb.bed\n",
    "TM_parsDict={}\n",
    "flagDict={\"o\":\"outside\",\"T\":\"TMhelix\",\"i\":\"inside\",\"s\":\"signal\"}\n",
    "'''\n",
    "    parser the tranmembe.bed file\n",
    "    TM_flag=outside,TMhelix,inside\n",
    "    outside:o\n",
    "    TMhelix:t\n",
    "    inside:i\n",
    "'''\n",
    "with open(trans_memb,\"r\") as tmf:\n",
    "    for line in tmf.readlines():\n",
    "        if line.startswith(\"sp|\"):\n",
    "            seqid = line.split(\"\\t\")[0].split(\"|\")[1]\n",
    "            if seqid not in TM_parsDict.keys():\n",
    "                TM_parsDict[seqid] = \"\"\n",
    "            pos1 = int(line.split(\"\\t\")[1])\n",
    "            pos2 = int(line.split(\"\\t\")[2])\n",
    "            TM_flag = line.split(\"\\t\")[3][0]\n",
    "            TM_parsDict[seqid] += TM_flag*(1+pos2-pos1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0c525-c8fc-4912-9dba-2c4dc2b6f6e4",
   "metadata": {},
   "source": [
    "## Step2: Parser the Homologous_peptide.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223fc787-7c35-4d15-85a8-01f1a46ffee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser the Homologous_peptide.bed\n",
    "if (homobed_or_blasp == \"homobed\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "    Homobed_parsDict={}\n",
    "    with open(homo_bed,\"r\") as hmf:\n",
    "        for line in hmf.readlines():\n",
    "            if line.startswith(\"sp|\"):\n",
    "                #print(line)\n",
    "                seqid = line.split(\"\\t\")[0].split(\"|\")[1]\n",
    "                if seqid not in Homobed_parsDict.keys():\n",
    "                    length = len(TM_parsDict[seqid])\n",
    "                    Homobed_parsDict[seqid] = [0]*length\n",
    "                pos1 = int(line.split(\"\\t\")[1])-1\n",
    "                pos2 = int(line.split(\"\\t\")[2])-1\n",
    "                homoid = line.split(\"\\t\")[3]\n",
    "                for pos in range(pos1,pos2):\n",
    "                    #print(pos)\n",
    "                    if Homobed_parsDict[seqid][pos] == 0:\n",
    "                        Homobed_parsDict[seqid][pos] = [homoid]\n",
    "                    else:\n",
    "                        Homobed_parsDict[seqid][pos].append(homoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "533727bd-c95a-45d7-af8f-890cafaa40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "QEQ92113\n"
     ]
    }
   ],
   "source": [
    "## Parser the peptide_netMHC.blastp\n",
    "if (homobed_or_blasp == \"homoblastp\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "    Homoblastp_parsDict={}\n",
    "    headname= [\"qseqid\",\"sseqid\",\"pident\",\"length\",\"mismatch\",\"gapopen\",\"qstart\",\"qend\",\"sstart\",\"send\",\"evalue\",\"bitscore\"]\n",
    "    blastdf = pd.read_csv(homo_blastp,sep=\"\\t\",names=headname)\n",
    "    blastdf[[\"protein\",\"peptide\"]] = blastdf.qseqid.str.split(\":\",expand=True)\n",
    "    #print(blastdf.head(10))\n",
    "    blastdf[\"proteinUnipID\"] = blastdf.protein.str.split(\"_\").str[1]\n",
    "    #print(blastdf.proteinUnipID.unique().tolist())\n",
    "    proteinlist = blastdf.proteinUnipID.unique().tolist()\n",
    "    selfUniproList = []\n",
    "    for proteinid in proteinlist:\n",
    "        # calculate the self \n",
    "        qblastdf = blastdf[blastdf[\"proteinUnipID\"]==proteinid]\n",
    "        homoRefseries = qblastdf.sseqid.value_counts()\n",
    "        # calculate the query number (or bin numbers)\n",
    "        querynum = len(qblastdf.qseqid.unique())\n",
    "        # find those reference id which is the query ploymer \n",
    "        selfUniproID = homoRefseries[homoRefseries>querynum*0.9].index.tolist()\n",
    "        selfUniproList += selfUniproID\n",
    "        print(selfUniproID)\n",
    "    print(selfUniproList)\n",
    " \n",
    "    # remove those aligned lines which reference is it's self\n",
    "    noSelfBlastdf = blastdf[~blastdf.sseqid.isin(selfUniproList)]\n",
    "    # select those aligned lines which pident bigger than cutoff\n",
    "    noSelfHomodf = noSelfBlastdf[noSelfBlastdf.pident > identity] # identity=65\n",
    "    \n",
    "    noSelfHomodf2 = noSelfHomodf[[\"proteinUnipID\",\"peptide\",\"sseqid\"]]\n",
    "    #print(noSelfHomodf2.head(20))\n",
    "    for proteinid in proteinlist:\n",
    "        print(proteinid)\n",
    "        noSelfHomodf2_p = noSelfHomodf2[noSelfHomodf2[\"proteinUnipID\"]==proteinid]\n",
    "        peptidelist = noSelfHomodf2_p.peptide.unique().tolist()\n",
    "        peptidesseqiddict = {}\n",
    "        for peptide in peptidelist:\n",
    "            sseqidlist = noSelfHomodf2_p[noSelfHomodf2_p[\"peptide\"]==peptide].sseqid.tolist()\n",
    "            peptidesseqiddict[peptide] = sseqidlist\n",
    "            Homoblastp_parsDict[proteinid] = peptidesseqiddict\n",
    "    #print(Homoblastp_parsDict)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec25b4e3-6e3f-4b31-8567-4b5b42df6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Homoblastp_parsDict[\"Q96A99\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300eaed-b695-4c94-8adf-543b1a94d99c",
   "metadata": {},
   "source": [
    "## Step3: Parser the enzymedigest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cac6839-b048-48c8-b400-250efe4dfd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser the enzymedigest file\n",
    "##适用于TAA的分析\n",
    "EnzDigeDict={}\n",
    "with open(enzymedigest,\"r\") as enzymef:\n",
    "    for line in enzymef.readlines():\n",
    "        refseq = re.split(',\"\\[',line)[0].split(\",\")[-1]\n",
    "        refid = re.split(',\"\\[',line)[0].split(\"|\")[1]\n",
    "        seqlist = re.split(',\"\\[',line)[1].strip().replace(']\"','').replace(\"'\",\"\").split(\",\")\n",
    "        EnzDigeDict[refid]=seqlist\n",
    "#print(EnzDigeDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e4d298-27d6-4f4a-bff8-80ffbd7e5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/jovyan/work/02.ResDev/12.TAA_epitope_human/05.AML_TAA_Epitope/06.EnzymeDisgest/protein.merge.enzymedigest': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "ls /home/jovyan/work/02.ResDev/12.TAA_epitope_human/05.AML_TAA_Epitope/06.EnzymeDisgest/protein.merge.enzymedigest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34cc7a-5670-4523-845c-0f332e303583",
   "metadata": {},
   "source": [
    "## Step4: Parse the Antigen Presentation of FIONA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd962990-6270-4564-bcae-16692e7ef88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## Parser the AP result of FIONA\\nAP_Fiona = {}\\nwith open(APres_FIONA,\"r\") as APresFiona:\\n    for line in APresFiona.readlines():\\n        #print(line)\\n        line = line.replace(\"|\",\"_\").rstrip()\\n        #print(line)\\n        seqid = line.split(\"_\")[1]\\n        peptide = line.split(\",\")[1]\\n        genetype = line.split(\",\")[2].replace(\"-\",\"\")\\n        Apres = line.split(\",\")[3]\\n        \\n        if seqid not in AP_Fiona.keys():\\n            AP_Fiona[seqid] = {}\\n            AP_Fiona[seqid][\":\".join([peptide,genetype])] = Apres\\n        else:\\n            AP_Fiona[seqid][\":\".join([peptide,genetype])] = Apres\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## Parser the AP result of FIONA\n",
    "AP_Fiona = {}\n",
    "with open(APres_FIONA,\"r\") as APresFiona:\n",
    "    for line in APresFiona.readlines():\n",
    "        #print(line)\n",
    "        line = line.replace(\"|\",\"_\").rstrip()\n",
    "        #print(line)\n",
    "        seqid = line.split(\"_\")[1]\n",
    "        peptide = line.split(\",\")[1]\n",
    "        genetype = line.split(\",\")[2].replace(\"-\",\"\")\n",
    "        Apres = line.split(\",\")[3]\n",
    "        \n",
    "        if seqid not in AP_Fiona.keys():\n",
    "            AP_Fiona[seqid] = {}\n",
    "            AP_Fiona[seqid][\":\".join([peptide,genetype])] = Apres\n",
    "        else:\n",
    "            AP_Fiona[seqid][\":\".join([peptide,genetype])] = Apres\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267fffee-9e6e-491f-8b37-31685533f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(AP_Fiona)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a001c-8f73-40a8-b885-8fd0141b889d",
   "metadata": {},
   "source": [
    "## Step5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "040d2680-3aa3-4c0a-95fa-f737ff0506ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_QEQ92113_G_p_MHCI_HLA-A*02:06.netMHC.csv\n"
     ]
    }
   ],
   "source": [
    "## Parser the netMHC.csv\n",
    "mergeoutfile =  open(outpath+\"/MHCI_Epitopeonly_SB_WB.csv\",\"w\")\n",
    "filenum = 0\n",
    "for file in glob.glob(path_mhcI + \"/*.netMHC.csv\"):\n",
    "    filenum +=1\n",
    "    filename= os.path.basename(file)\n",
    "    print(filename)\n",
    "    outfile = open(outpath1+\"/\"+filename,\"w\")\n",
    "    with open(file,\"r\") as eptf:\n",
    "        for line in eptf.readlines():\n",
    "            #print(line)\n",
    "            itemlist = line.rstrip().split(\",\")\n",
    "            \"\"\"\n",
    "            itemlist is the line content of netMHC result\n",
    "            \"\"\"\n",
    "            if line.startswith(\"Pos\"):\n",
    "                appendlist = [\"AP_result_of_FIONA\",\"TransMemb\",\"InCutmerRate\",\"InCutmerRegion\",\"HomoExsit\",\"HomoId\"]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                if filenum == 1:\n",
    "                    mergeoutfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "            else:\n",
    "                pos1 = int(itemlist[0])-1\n",
    "                peptide = itemlist[2]\n",
    "                pos2 = pos1 + len(peptide)\n",
    "                seqid = itemlist[10].split(\"_\")[1]\n",
    "                midpos = int((pos1+pos2)/2)\n",
    "                genetype =  itemlist[1].replace(\"-\",\"\")\n",
    "                \n",
    "                #print(seqid)\n",
    "                \n",
    "                ## get AP result of FIONA\n",
    "                #APres_Fiona = AP_Fiona[seqid][\":\".join([peptide,genetype])]\n",
    "                APres_Fiona = \"--\"\n",
    "                \n",
    "                ## get Transmembrane info\n",
    "                TM_f = TM_parsDict[seqid][midpos]\n",
    "                TM_flag = flagDict[TM_f]\n",
    "                \n",
    "                ## get enzymedigest info\n",
    "                size0 = 0\n",
    "                overseq0 = \"\"\n",
    "                for seq in EnzDigeDict[seqid]:\n",
    "                    size,overseq = get_overlap(peptide,seq)\n",
    "                    if size > size0:\n",
    "                        size0 = size\n",
    "                        overseq0 = overseq\n",
    "                Cut_flag = '\"'+str(size0)+\"//\"+str(len(peptide))+'\"'\n",
    "                Cut_seq = overseq0\n",
    "                \n",
    "                ## get homolgous info\n",
    "                if (homobed_or_blasp == \"homobed\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_bed(Homo_parsDict,seqid,pos1,pos2)\n",
    "                elif (homobed_or_blasp == \"homoblastp\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_blastp(Homoblastp_parsDict,seqid,peptide)\n",
    "                    \n",
    "                ##  output the results with filtering the \"SB\" lines\n",
    "                if (itemlist[-1] == \"SB\") or (itemlist[-1] == \"WB\"):\n",
    "                    appendlist = [APres_Fiona,TM_flag,Cut_flag,Cut_seq,HomoEx,Homo_flag]\n",
    "                    mergeoutfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                else:\n",
    "                    appendlist = [\"\",APres_Fiona,TM_flag,\"\",\"\",HomoEx,Homo_flag]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a9d9a9b-65b7-401c-8988-3ab3a31decbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_QEQ92113_G_p_MHCII_DRB1_0901.netMHC.csv\n"
     ]
    }
   ],
   "source": [
    "## Parser the netMHC.csv\n",
    "mergeoutfile2 =  open(outpath+\"/MHCII_Epitope_only_SB_WB.csv\",\"w\")\n",
    "filenum = 0\n",
    "for file in glob.glob(path_mhcII + \"/*.netMHC.csv\"):\n",
    "    filenum += 1\n",
    "    filename= os.path.basename(file)\n",
    "    print(filename)\n",
    "    outfile = open(outpath2+\"/\"+filename,\"w\")\n",
    "    with open(file,\"r\") as eptf:\n",
    "        for line in eptf.readlines():\n",
    "            itemlist = line.rstrip().split(\",\")\n",
    "            #print(itemlist)\n",
    "            if line.startswith(\"Pos\"):\n",
    "                appendlist = [\"AP_result_of_FIONA\",\"TransMemb\",\"InCutmerRate\",\"InCutmerRegion\",\"HomoExsit\",\"HomoId\"]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                if filenum == 1:\n",
    "                    mergeoutfile2.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "            else:\n",
    "                pos1 = int(itemlist[0])-1\n",
    "                peptide = itemlist[2]\n",
    "                pos2 = pos1 + len(peptide)\n",
    "                seqid = itemlist[6].split(\"|\")[1]\n",
    "                midpos = int((pos1+pos2)/2)\n",
    "                genetype =  itemlist[1].replace(\"-\",\"\")\n",
    "                \n",
    "                ## get AP result of FIONA\n",
    "                #APres_Fiona = AP_Fiona[seqid][\":\".join([peptide,genetype])]              \n",
    "                APres_Fiona = \"--\"              \n",
    "                    \n",
    "                ## get Transmembrane info\n",
    "                TM_f = TM_parsDict[seqid][midpos]\n",
    "                TM_flag = flagDict[TM_f]\n",
    "                \n",
    "                ## get enzymedigest info\n",
    "                size0 = 0\n",
    "                overseq0 = \"\"\n",
    "                for seq in EnzDigeDict[seqid]:\n",
    "                    size,overseq = get_overlap(peptide,seq)\n",
    "                    if size > size0:\n",
    "                        size0 = size\n",
    "                        overseq0 = overseq\n",
    "                Cut_flag = '\"'+str(size0)+\"//\"+str(len(peptide))+'\"'\n",
    "                Cut_seq = overseq0\n",
    "                \n",
    "                ## get homolgous info\n",
    "                if (homobed_or_blasp == \"homobed\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_bed(Homo_parsDict,seqid,pos1,pos2)\n",
    "                elif (homobed_or_blasp == \"homoblastp\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_blastp(Homoblastp_parsDict,seqid,peptide)\n",
    "                        \n",
    "                ##  output the results with filtering the \"SB\" lines\n",
    "                if (itemlist[-1] == \"SB\") or (itemlist[-1] == \"WB\"):\n",
    "                    appendlist = [APres_Fiona,TM_flag,Cut_flag,Cut_seq,HomoEx,Homo_flag]\n",
    "                    mergeoutfile2.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                else:\n",
    "                    appendlist = [\"\",APres_Fiona,TM_flag,\"\",\"\",HomoEx,Homo_flag]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e5b61fc-563b-4c34-adc9-4f1e2ee7dea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sp_QEQ92113_G_p']\n",
      "0    HLA-A\\*02:06\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_SB_WB = pd.read_csv(outpath+\"/MHCI_Epitopeonly_SB_WB.csv\")\n",
    "proteinlist = list(df_SB_WB[\"Identity\"].unique())\n",
    "print(proteinlist)\n",
    "for seqid in proteinlist:\n",
    "    try:\n",
    "        os.mkdir(outpath+\"/\"+seqid)\n",
    "    except:\n",
    "        pass\n",
    "    seqid_df = df_SB_WB[df_SB_WB[\"Identity\"].str.contains(seqid)]\n",
    "    MHClist= pd.Series(seqid_df[\"MHC\"].unique())\n",
    "    MHClist2 = MHClist.str.replace('*', r'\\*', regex=True)\n",
    "    print(MHClist2)\n",
    "    \n",
    "    for MHCid,MHCid2 in zip(MHClist,MHClist2):\n",
    "        seqid_mhcid_df = seqid_df[seqid_df[\"MHC\"].str.contains(MHCid2)]\n",
    "        seqid_mhcid_df.to_csv(outpath+\"/\"+seqid+\"/\"+seqid+\"_MHCI_\"+MHCid+\".netMHC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46de6a-bbba-46de-8688-23e41edd2615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_921546/692703209.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_SB_WB[\"Identity\"] = df_SB_WB[\"Identity\"].str.replace(\"|\",\"_\")\n"
     ]
    }
   ],
   "source": [
    "df_SB_WB = pd.read_csv(outpath+\"/MHCII_Epitope_only_SB_WB.csv\")\n",
    "df_SB_WB[\"Identity\"] = df_SB_WB[\"Identity\"].str.replace(\"|\",\"_\")\n",
    "proteinlist = list(df_SB_WB[\"Identity\"].unique())\n",
    "for seqid in proteinlist:\n",
    "    try:\n",
    "        os.mkdir(outpath+\"/\"+seqid2)\n",
    "    except:\n",
    "        pass\n",
    "    seqid_df = df_SB_WB[df_SB_WB[\"Identity\"].str.contains(seqid)]\n",
    "    MHClist= (seqid_df[\"MHC\"].unique())\n",
    "    for MHCid in MHClist:\n",
    "        seqid_mhcid_df = seqid_df[seqid_df[\"MHC\"].str.contains(MHCid)]\n",
    "        seqid_mhcid_df.to_csv(outpath+\"/\"+seqid+\"/\"+seqid+\"_MHCII_\"+MHCid+\".netMHC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd905697-0a48-42c9-b04f-3e2aa4a0409d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
