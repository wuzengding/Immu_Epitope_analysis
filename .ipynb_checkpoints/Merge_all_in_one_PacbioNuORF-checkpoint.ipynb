{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708f6436-58a8-43a7-a5ac-0802fef34f95",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9af32c5-609b-43fa-84e9-227a1e036247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fded304-7e4d-4a0f-8a7f-4a8c414a6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config the path where multiple files contained.\n",
    "## NEED modify every time it runs !!!\n",
    "\n",
    "path = \"/home/jovyan/work/02.ResDev/03.MC38_neoantigen/Inhouse_RNC_pacbio_20221207/MC38_xenograft_Case/results/09.Antigen_presentation\"\n",
    "homobed_or_blasp = \"homoblastp\"\n",
    "'''\n",
    "select list is \"homobed\",\"homoblastp\",\"bedblastp\"\n",
    "\"homobed\" means homobed file as input only\n",
    "\"homoblastp\" means homoblastp file as input only\n",
    "\"bedblastp\" means homobed and homoblastp files both as input\n",
    "'''\n",
    "identity = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f26d716-39c6-4155-b854-ddd8315f399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config input files under the given path.\n",
    "## No NEED modify every time it runs !!!\n",
    "\n",
    "path_mhcI = path + \"/02.protein_antigen_prediction/parsed_res_MHCI\"\n",
    "path_mhcII = path + \"/02.protein_antigen_prediction/parsed_res_MHCII\"\n",
    "trans_memb = path + \"/04.TransMembrane.DeepTMHMM/TransMembrane.bed\"\n",
    "enzymedigest = path + \"/05.EnzymeDigest/protein.merge.enzymedigest\"\n",
    "\n",
    "if homobed_or_blasp==\"homobed\":\n",
    "    homo_bed = path + \"/03.homologous/homo_peptide.bed\"\n",
    "elif homobed_or_blasp== \"homoblastp\":\n",
    "    homo_blastp = path + \"/03.homologous/peptide_netMHC.blastp\"\n",
    "elif homobed_or_blasp== \"bedblastp\":\n",
    "    homo_bed = path + \"/03.homologous/homo_peptide.bed\"\n",
    "    homo_blastp = path + \"/03.homologous/peptide_netMHC.blastp\"\n",
    "\n",
    "outpath = path + \"/06.Deliverables/EpitopePresent\"\n",
    "outpath1 = path + \"/06.Deliverables/EpitopePresent/MHCI\"\n",
    "outpath2 = path + \"/06.Deliverables/EpitopePresent/MHCII\"\n",
    "try:\n",
    "    os.mkdir(outpath)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(outpath1)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(outpath2)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261617f8-8d47-40d4-9614-2ab7215de8df",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cc1f2d-ecbb-4d7f-a4d8-a017f64dc1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 'GGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTC')\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "def get_overlap(s1, s2):\n",
    "    s = difflib.SequenceMatcher(None, s1, s2)\n",
    "    pos_a, pos_b, size = s.find_longest_match(0, len(s1), 0, len(s2)) \n",
    "    return(size,s1[pos_a:pos_a+size])\n",
    "s1 = \"CGATTCCAGGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTC\"\n",
    "s2 = \"GGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTCGTCCAGACCCCTAGC\"\n",
    "\n",
    "print(get_overlap(s1, s2)) # GGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6a9f2c-4e12-4e74-93f6-c7367f0af142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homodict_bed(Homo_parsDict,seqid,pos1,pos2):\n",
    "    checklist = [homo_f==0 for homo_f in Homo_parsDict[seqid][pos1:pos2]]\n",
    "    if  sum(checklist)/(pos2-pos1) >= 0.05:\n",
    "        HomoEx = \"N\"\n",
    "        Homo_flag = \"\"\n",
    "    else:\n",
    "        HomoEx = \"Y\"\n",
    "        flagtemp_list = []\n",
    "        for flag in Homo_parsDict[seqid][pos1:pos2]:\n",
    "            if flag !=0:\n",
    "                flagtemp_list += flag\n",
    "        Homo_flag = \";\".join(list(dict.fromkeys(flagtemp_list)))\n",
    "    return(HomoEx,Homo_flag)\n",
    "\n",
    "def get_homodict_blastp(Homoblastp_parsDict,seqid,peptide):\n",
    "    try:\n",
    "        homolist = Homoblastp_parsDict[seqid][peptide]\n",
    "        if len(homolist) == 0:\n",
    "            Homo_flag = \"\"\n",
    "            HomoEx = \"N\"\n",
    "        else:\n",
    "            Homo_flag = ';'.join(homolist)\n",
    "            HomoEx = \"Y\"\n",
    "    except:\n",
    "        Homo_flag = \"\"\n",
    "        HomoEx = \"N\"\n",
    "    return(HomoEx,Homo_flag)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7a83e-3d7c-4ea0-998c-02b336d0bd22",
   "metadata": {},
   "source": [
    "## Step1: Parser the TransMemb.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd475435-2a50-41ad-8d2b-077906ba6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser the TransMemb.bed\n",
    "TM_parsDict={}\n",
    "flagDict={\"o\":\"outside\",\"T\":\"TMhelix\",\"i\":\"inside\",\"s\":\"signal\"}\n",
    "'''\n",
    "    parser the tranmembe.bed file\n",
    "    TM_flag=outside,TMhelix,inside\n",
    "    outside:o\n",
    "    TMhelix:t\n",
    "    inside:i\n",
    "'''\n",
    "with open(trans_memb,\"r\") as tmf:\n",
    "    for line in tmf.readlines():\n",
    "        if line.startswith(\"sp|\"):\n",
    "            seqid = line.split(\"\\t\")[0].split(\"|\")[1]\n",
    "            if seqid not in TM_parsDict.keys():\n",
    "                TM_parsDict[seqid] = \"\"\n",
    "            pos1 = int(line.split(\"\\t\")[1])\n",
    "            pos2 = int(line.split(\"\\t\")[2])\n",
    "            TM_flag = line.split(\"\\t\")[3][0]\n",
    "            TM_parsDict[seqid] += TM_flag*(1+pos2-pos1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0c525-c8fc-4912-9dba-2c4dc2b6f6e4",
   "metadata": {},
   "source": [
    "## Step2: Parser the Homologous_peptide.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223fc787-7c35-4d15-85a8-01f1a46ffee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser the Homologous_peptide.bed\n",
    "if (homobed_or_blasp == \"homobed\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "    Homobed_parsDict={}\n",
    "    with open(homo_bed,\"r\") as hmf:\n",
    "        for line in hmf.readlines():\n",
    "            if line.startswith(\"sp|\"):\n",
    "                #print(line)\n",
    "                seqid = line.split(\"\\t\")[0].split(\"|\")[1]\n",
    "                if seqid not in Homobed_parsDict.keys():\n",
    "                    length = len(TM_parsDict[seqid])\n",
    "                    Homobed_parsDict[seqid] = [0]*length\n",
    "                pos1 = int(line.split(\"\\t\")[1])-1\n",
    "                pos2 = int(line.split(\"\\t\")[2])-1\n",
    "                homoid = line.split(\"\\t\")[3]\n",
    "                for pos in range(pos1,pos2):\n",
    "                    #print(pos)\n",
    "                    if Homobed_parsDict[seqid][pos] == 0:\n",
    "                        Homobed_parsDict[seqid][pos] = [homoid]\n",
    "                    else:\n",
    "                        Homobed_parsDict[seqid][pos].append(homoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "533727bd-c95a-45d7-af8f-890cafaa40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q9DCL9']\n",
      "['Q8BGY4']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Q9DCL9', 'Q8BGY4']\n",
      "1517\n",
      "1528\n",
      "1596\n",
      "349\n",
      "458\n",
      "lcl\n"
     ]
    }
   ],
   "source": [
    "## Parser the peptide_netMHC.blastp\n",
    "if (homobed_or_blasp == \"homoblastp\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "    Homoblastp_parsDict={}\n",
    "    headname= [\"qseqid\",\"sseqid\",\"pident\",\"length\",\"mismatch\",\"gapopen\",\"qstart\",\"qend\",\"sstart\",\"send\",\"evalue\",\"bitscore\"]\n",
    "    blastdf = pd.read_csv(homo_blastp,sep=\"\\t\",names=headname)\n",
    "    blastdf[[\"protein\",\"peptide\"]] = blastdf.qseqid.str.split(\":\",expand=True)\n",
    "    #print(blastdf.head(10))\n",
    "    blastdf[\"proteinUnipID\"] = blastdf.protein.str.split(\"_\").str[1]\n",
    "    #print(blastdf.proteinUnipID.unique().tolist())\n",
    "    proteinlist = blastdf.proteinUnipID.unique().tolist()\n",
    "    selfUniproList = []\n",
    "    for proteinid in proteinlist:\n",
    "        # calculate the self \n",
    "        qblastdf = blastdf[blastdf[\"proteinUnipID\"]==proteinid]\n",
    "        homoRefseries = qblastdf.sseqid.value_counts()\n",
    "        # calculate the query number (or bin numbers)\n",
    "        querynum = len(qblastdf.qseqid.unique())\n",
    "        # find those reference id which is the query ploymer \n",
    "        selfUniproID = homoRefseries[homoRefseries>querynum*0.9].index.tolist()\n",
    "        selfUniproList += selfUniproID\n",
    "        print(selfUniproID)\n",
    "    print(selfUniproList)\n",
    " \n",
    "    # remove those aligned lines which reference is it's self\n",
    "    noSelfBlastdf = blastdf[~blastdf.sseqid.isin(selfUniproList)]\n",
    "    # select those aligned lines which pident bigger than cutoff\n",
    "    noSelfHomodf = noSelfBlastdf[noSelfBlastdf.pident > identity] # identity=65\n",
    "    \n",
    "    noSelfHomodf2 = noSelfHomodf[[\"proteinUnipID\",\"peptide\",\"sseqid\"]]\n",
    "    #print(noSelfHomodf2.head(20))\n",
    "    for proteinid in proteinlist:\n",
    "        print(proteinid)\n",
    "        noSelfHomodf2_p = noSelfHomodf2[noSelfHomodf2[\"proteinUnipID\"]==proteinid]\n",
    "        peptidelist = noSelfHomodf2_p.peptide.unique().tolist()\n",
    "        peptidesseqiddict = {}\n",
    "        for peptide in peptidelist:\n",
    "            sseqidlist = noSelfHomodf2_p[noSelfHomodf2_p[\"peptide\"]==peptide].sseqid.tolist()\n",
    "            peptidesseqiddict[peptide] = sseqidlist\n",
    "            Homoblastp_parsDict[proteinid] = peptidesseqiddict\n",
    "    #print(Homoblastp_parsDict)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec25b4e3-6e3f-4b31-8567-4b5b42df6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Homoblastp_parsDict[\"Q96A99\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300eaed-b695-4c94-8adf-543b1a94d99c",
   "metadata": {},
   "source": [
    "## Step3: Parser the enzymedigest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cac6839-b048-48c8-b400-250efe4dfd06",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m refseq \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m,line)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m refid \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m,line)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m seqlist \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m[\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m EnzDigeDict[refid]\u001b[38;5;241m=\u001b[39mseqlist\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## Parser the enzymedigest file\n",
    "##适用于TAA的分析\n",
    "EnzDigeDict={}\n",
    "with open(enzymedigest,\"r\") as enzymef:\n",
    "    for line in enzymef.readlines():\n",
    "        refseq = re.split(',\"\\[',line)[0].split(\",\")[-1]\n",
    "        refid = re.split(',\"\\[',line)[0].split(\"|\")[1]\n",
    "        seqlist = re.split(',\"\\[',line)[1].strip().replace(']\"','').replace(\"'\",\"\").split(\",\")\n",
    "        EnzDigeDict[refid]=seqlist\n",
    "#print(EnzDigeDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b836a-217b-4169-ac9e-fba1fa43ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/jovyan/work/02.ResDev/12.TAA_epitope_human/05.AML_TAA_Epitope/06.EnzymeDisgest/protein.merge.enzymedigest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d2680-3aa3-4c0a-95fa-f737ff0506ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser the netMHC.csv\n",
    "mergeoutfile =  open(outpath+\"/MHCI_Epitopeonly_SB_WB.csv\",\"w\")\n",
    "filenum = 0\n",
    "for file in glob.glob(path_mhcI + \"/*.netMHC.csv\"):\n",
    "    filenum +=1\n",
    "    filename= os.path.basename(file)\n",
    "    outfile = open(outpath1+\"/\"+filename,\"w\")\n",
    "    with open(file,\"r\") as eptf:\n",
    "        for line in eptf.readlines():\n",
    "            itemlist = line.rstrip().split(\",\")\n",
    "            \"\"\"\n",
    "            itemlist is the line content of netMHC result\n",
    "            \"\"\"\n",
    "            if line.startswith(\"Pos\"):\n",
    "                appendlist = [\"TransMemb\",\"InCutmerRate\",\"InCutmerRegion\",\"HomoExsit\",\"HomoId\"]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                if filenum == 1:\n",
    "                    mergeoutfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "            else:\n",
    "                pos1 = int(itemlist[0])-1\n",
    "                peptide = itemlist[2]\n",
    "                pos2 = pos1 + len(peptide)\n",
    "                seqid = itemlist[10].split(\"_\")[1]\n",
    "                midpos = int((pos1+pos2)/2)\n",
    "                \n",
    "                ## get Transmembrane info\n",
    "                TM_f = TM_parsDict[seqid][midpos]\n",
    "                TM_flag = flagDict[TM_f]\n",
    "                \n",
    "                ## get enzymedigest info\n",
    "                size0 = 0\n",
    "                overseq0 = \"\"\n",
    "                for seq in EnzDigeDict[seqid]:\n",
    "                    size,overseq = get_overlap(peptide,seq)\n",
    "                    if size > size0:\n",
    "                        size0 = size\n",
    "                        overseq0 = overseq\n",
    "                Cut_flag = '\"'+str(size0)+\"//\"+str(len(peptide))+'\"'\n",
    "                Cut_seq = overseq0\n",
    "                \n",
    "                ## get homolgous info\n",
    "                if (homobed_or_blasp == \"homobed\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_bed(Homo_parsDict,seqid,pos1,pos2)\n",
    "                elif (homobed_or_blasp == \"homoblastp\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_blastp(Homoblastp_parsDict,seqid,peptide)\n",
    "                ##  output the results with filtering the \"SB\" lines\n",
    "                if (itemlist[-1] == \"SB\") or (itemlist[-1] == \"WB\"):\n",
    "                    appendlist = [TM_flag,Cut_flag,Cut_seq,HomoEx,Homo_flag]\n",
    "                    mergeoutfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                else:\n",
    "                    appendlist = [\"\",TM_flag,Cut_flag,HomoEx,Homo_flag]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d9a9b-65b7-401c-8988-3ab3a31decbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser the netMHC.csv\n",
    "mergeoutfile2 =  open(outpath+\"/MHCII_Epitope_only_SB_WB.csv\",\"w\")\n",
    "filenum = 0\n",
    "for file in glob.glob(path_mhcII + \"/*.netMHC.csv\"):\n",
    "    filenum += 1\n",
    "    filename= os.path.basename(file)\n",
    "    outfile = open(outpath2+\"/\"+filename,\"w\")\n",
    "    with open(file,\"r\") as eptf:\n",
    "        for line in eptf.readlines():\n",
    "            itemlist = line.rstrip().split(\",\")\n",
    "            if line.startswith(\"Pos\"):\n",
    "                appendlist = [\"TransMemb\",\"InCutmerRate\",\"InCutmerRegion\",\"HomoExsit\",\"HomoId\"]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                if filenum == 1:\n",
    "                    mergeoutfile2.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "            else:\n",
    "                pos1 = int(itemlist[0])-1\n",
    "                peptide = itemlist[2]\n",
    "                pos2 = pos1 + len(peptide)\n",
    "                seqid = itemlist[6].split(\"|\")[1]\n",
    "                midpos = int((pos1+pos2)/2)\n",
    "                \n",
    "                ## get Transmembrane info\n",
    "                TM_f = TM_parsDict[seqid][midpos]\n",
    "                TM_flag = flagDict[TM_f]\n",
    "                \n",
    "                ## get enzymedigest info\n",
    "                size0 = 0\n",
    "                overseq0 = \"\"\n",
    "                for seq in EnzDigeDict[seqid]:\n",
    "                    size,overseq = get_overlap(peptide,seq)\n",
    "                    if size > size0:\n",
    "                        size0 = size\n",
    "                        overseq0 = overseq\n",
    "                Cut_flag = '\"'+str(size0)+\"//\"+str(len(peptide))+'\"'\n",
    "                Cut_seq = overseq0\n",
    "                \n",
    "                ## get homolgous info\n",
    "                if (homobed_or_blasp == \"homobed\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_bed(Homo_parsDict,seqid,pos1,pos2)\n",
    "                elif (homobed_or_blasp == \"homoblastp\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_blastp(Homoblastp_parsDict,seqid,peptide)\n",
    "                        \n",
    "                ##  output the results with filtering the \"SB\" lines\n",
    "                if (itemlist[-1] == \"SB\") or (itemlist[-1] == \"WB\"):\n",
    "                    appendlist = [TM_flag,Cut_flag,Cut_seq,HomoEx,Homo_flag]\n",
    "                    mergeoutfile2.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                else:\n",
    "                    appendlist = [\"\",TM_flag,HomoEx,Homo_flag]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "    outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
