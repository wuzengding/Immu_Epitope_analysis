{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708f6436-58a8-43a7-a5ac-0802fef34f95",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9af32c5-609b-43fa-84e9-227a1e036247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fded304-7e4d-4a0f-8a7f-4a8c414a6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config the path where multiple files contained.\n",
    "## NEED modify every time it runs !!!\n",
    "\n",
    "path = \"/home/jovyan/work/10.data_CODA_ahslyy/0014215947_CA/results/09.EpitopePrediction\"\n",
    "homobed_or_blasp = \"homoblastp\"\n",
    "'''\n",
    "select list is \"homobed\",\"homoblastp\",\"bedblastp\"\n",
    "\"homobed\" means homobed file as input only\n",
    "\"homoblastp\" means homoblastp file as input only\n",
    "\"bedblastp\" means homobed and homoblastp files both as input\n",
    "'''\n",
    "identity = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f26d716-39c6-4155-b854-ddd8315f399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config input files under the given path.\n",
    "## No NEED modify every time it runs !!!\n",
    "\n",
    "path_mhcI = path + \"/02.protein_antigen_prediction/parsed_res_MHCI\"\n",
    "path_mhcII = path + \"/02.protein_antigen_prediction/parsed_res_MHCII\"\n",
    "trans_memb = path + \"/04.TransMembrane.DeepTMHMM/TransMembrane.bed\"\n",
    "enzymedigest = path + \"/05.EnzymeDigest/protein.merge.enzymedigest\"\n",
    "\n",
    "if homobed_or_blasp==\"homobed\":\n",
    "    homo_bed = path + \"/03.homologous/homo_peptide.bed\"\n",
    "elif homobed_or_blasp== \"homoblastp\":\n",
    "    homo_blastp = path + \"/03.homologous/peptide.netMHC.aa.blastp\"\n",
    "elif homobed_or_blasp== \"bedblastp\":\n",
    "    homo_bed = path + \"/03.homologous/homo_peptide.bed\"\n",
    "    homo_blastp = path + \"/03.homologous/peptide.netMHC.aa.blastp\"\n",
    "\n",
    "outpath = path + \"/06.Deliverables/EpitopePresent\"\n",
    "outpath1 = path + \"/06.Deliverables/EpitopePresent/MHCI\"\n",
    "outpath2 = path + \"/06.Deliverables/EpitopePresent/MHCII\"\n",
    "try:\n",
    "    os.mkdir(outpath)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(outpath1)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(outpath2)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261617f8-8d47-40d4-9614-2ab7215de8df",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cc1f2d-ecbb-4d7f-a4d8-a017f64dc1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 'GGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTC')\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "def get_overlap(s1, s2):\n",
    "    s = difflib.SequenceMatcher(None, s1, s2)\n",
    "    pos_a, pos_b, size = s.find_longest_match(0, len(s1), 0, len(s2)) \n",
    "    return(size,s1[pos_a:pos_a+size])\n",
    "s1 = \"CGATTCCAGGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTC\"\n",
    "s2 = \"GGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTCGTCCAGACCCCTAGC\"\n",
    "\n",
    "print(get_overlap(s1, s2)) # GGCTCCCCACGGGGTACCCATAACTTGACAGTAGATCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6a9f2c-4e12-4e74-93f6-c7367f0af142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homodict_bed(Homo_parsDict,seqid,pos1,pos2):\n",
    "    checklist = [homo_f==0 for homo_f in Homo_parsDict[seqid][pos1:pos2]]\n",
    "    if  sum(checklist)/(pos2-pos1) >= 0.05:\n",
    "        HomoEx = \"N\"\n",
    "        Homo_flag = \"\"\n",
    "    else:\n",
    "        HomoEx = \"Y\"\n",
    "        flagtemp_list = []\n",
    "        for flag in Homo_parsDict[seqid][pos1:pos2]:\n",
    "            if flag !=0:\n",
    "                flagtemp_list += flag\n",
    "        Homo_flag = \";\".join(list(dict.fromkeys(flagtemp_list)))\n",
    "    return(HomoEx,Homo_flag)\n",
    "\n",
    "def get_homodict_blastp(Homoblastp_parsDict,seqid,peptide):\n",
    "    try:\n",
    "        homolist = Homoblastp_parsDict[seqid][peptide]\n",
    "        if len(homolist) == 0:\n",
    "            Homo_flag = \"\"\n",
    "            HomoEx = \"N\"\n",
    "        else:\n",
    "            Homo_flag = ';'.join(homolist)\n",
    "            HomoEx = \"Y\"\n",
    "    except:\n",
    "        Homo_flag = \"\"\n",
    "        HomoEx = \"N\"\n",
    "    return(HomoEx,Homo_flag)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7a83e-3d7c-4ea0-998c-02b336d0bd22",
   "metadata": {},
   "source": [
    "## Step1: Parser the TransMemb.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd475435-2a50-41ad-8d2b-077906ba6c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB_151_COPA\n",
      "PB_1595COL10A1\n",
      "PB_1595COL10A1\n",
      "{'PB_151_COPA': 'iiiiiiiiiiiiiiiiiiiiiiii', 'PB_1595COL10A1': 'ssssssssssssssssssoooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo'}\n"
     ]
    }
   ],
   "source": [
    "## Parser the TransMemb.bed\n",
    "TM_parsDict={}\n",
    "flagDict={\"o\":\"outside\",\"T\":\"TMhelix\",\"i\":\"inside\",\"s\":\"signal\"}\n",
    "'''\n",
    "    parser the tranmembe.bed file\n",
    "    TM_flag=outside,TMhelix,inside\n",
    "    outside:o\n",
    "    TMhelix:t\n",
    "    inside:i\n",
    "'''\n",
    "with open(trans_memb,\"r\") as tmf:\n",
    "    for line in tmf.readlines():\n",
    "        ### 对文件第一行跳过\n",
    "        if line.startswith(\"track name=\"):\n",
    "            continue \n",
    "        ### 对用Sakit分析得到的蛋白，获取蛋白ID\n",
    "        elif line.startswith(\"PB\"):\n",
    "            seqid = line.split(\"\\t\")[0]\n",
    "            seqid = seqid.replace(\".\",\"_\")\n",
    "            seqid = \"_\".join(seqid.split(\"_\")[0:3])\n",
    "        ### 对根据protein ID分析得到的蛋白，获取蛋白ID\n",
    "        elif line.startswith(\"sp\"):\n",
    "            seqid = line.split(\"\\t\")[0]\n",
    "            seqid = seqid.replace(\"|\",\"_\")\n",
    "            seqid = \"_\".join(seqid.split(\"_\")[0:2])\n",
    "            \n",
    "        print(seqid)\n",
    "        ### \n",
    "        if seqid not in TM_parsDict.keys():\n",
    "            TM_parsDict[seqid] = \"\" ### 初始化 seqid在TM_parsDict的存储\n",
    "        pos1 = int(line.split(\"\\t\")[1])\n",
    "        pos2 = int(line.split(\"\\t\")[2])\n",
    "        TM_flag = line.split(\"\\t\")[3][0]\n",
    "        TM_parsDict[seqid] += TM_flag*(1+pos2-pos1)\n",
    "print(TM_parsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0c525-c8fc-4912-9dba-2c4dc2b6f6e4",
   "metadata": {},
   "source": [
    "## Step2: Parser the Homologous_peptide.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223fc787-7c35-4d15-85a8-01f1a46ffee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser the Homologous_peptide.bed\n",
    "if (homobed_or_blasp == \"homobed\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "    Homobed_parsDict={}\n",
    "    with open(homo_bed,\"r\") as hmf:\n",
    "        for line in hmf.readlines():\n",
    "            if line.startswith(\"sp|\"):\n",
    "                #print(line)\n",
    "                seqid = line.split(\"\\t\")[0].split(\"|\")[1]\n",
    "                if seqid not in Homobed_parsDict.keys():\n",
    "                    length = len(TM_parsDict[seqid])\n",
    "                    Homobed_parsDict[seqid] = [0]*length\n",
    "                pos1 = int(line.split(\"\\t\")[1])-1\n",
    "                pos2 = int(line.split(\"\\t\")[2])-1\n",
    "                homoid = line.split(\"\\t\")[3]\n",
    "                for pos in range(pos1,pos2):\n",
    "                    #print(pos)\n",
    "                    if Homobed_parsDict[seqid][pos] == 0:\n",
    "                        Homobed_parsDict[seqid][pos] = [homoid]\n",
    "                    else:\n",
    "                        Homobed_parsDict[seqid][pos].append(homoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "533727bd-c95a-45d7-af8f-890cafaa40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PB_151_COPA', 'PB_1595COL10A1']\n",
      "['Q8CIE6']\n",
      "PB_151_COPA\n",
      "PB_1595COL10A1\n"
     ]
    }
   ],
   "source": [
    "## Parser the peptide_netMHC.blastp\n",
    "if (homobed_or_blasp == \"homoblastp\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "    Homoblastp_parsDict={}\n",
    "    headname= [\"qseqid\",\"sseqid\",\"pident\",\"length\",\"mismatch\",\"gapopen\",\"qstart\",\"qend\",\"sstart\",\"send\",\"evalue\",\"bitscore\"]\n",
    "    blastdf = pd.read_csv(homo_blastp,sep=\"\\t\",names=headname)\n",
    "    blastdf[[\"protein\",\"peptide\"]] = blastdf.qseqid.str.split(\":\",expand=True)\n",
    "    #print(blastdf.head(10))\n",
    "    blastdf[\"proteinUnipID\"] = blastdf[\"protein\"].str.split(\"_\").apply(lambda x: \"_\".join(x[0:3]))\n",
    "    print(blastdf.proteinUnipID.unique().tolist())\n",
    "    proteinlist = blastdf.proteinUnipID.unique().tolist()\n",
    "    selfUniproList = []\n",
    "    for proteinid in proteinlist:\n",
    "        # calculate the self \n",
    "        qblastdf = blastdf[blastdf[\"proteinUnipID\"]==proteinid]\n",
    "        homoRefseries = qblastdf.sseqid.value_counts()\n",
    "        # calculate the query number (or bin numbers)\n",
    "        querynum = len(qblastdf.qseqid.unique())\n",
    "        # find those reference id which is the query ploymer \n",
    "        selfUniproID = homoRefseries[homoRefseries>querynum*0.9].index.tolist()\n",
    "        selfUniproList += selfUniproID\n",
    "    print(selfUniproList)\n",
    " \n",
    "    # remove those aligned lines which reference is it's self\n",
    "    noSelfBlastdf = blastdf[~blastdf.sseqid.isin(selfUniproList)]\n",
    "    # select those aligned lines which pident bigger than cutoff\n",
    "    noSelfHomodf = noSelfBlastdf[noSelfBlastdf.pident > identity] # identity=65\n",
    "    \n",
    "    noSelfHomodf2 = noSelfHomodf[[\"proteinUnipID\",\"peptide\",\"sseqid\"]]\n",
    "    #print(noSelfHomodf2.head(20))\n",
    "    for proteinid in proteinlist:\n",
    "        print(proteinid)\n",
    "        noSelfHomodf2_p = noSelfHomodf2[noSelfHomodf2[\"proteinUnipID\"]==proteinid]\n",
    "        peptidelist = noSelfHomodf2_p.peptide.unique().tolist()\n",
    "        peptidesseqiddict = {}\n",
    "        for peptide in peptidelist:\n",
    "            sseqidlist = noSelfHomodf2_p[noSelfHomodf2_p[\"peptide\"]==peptide].sseqid.tolist()\n",
    "            peptidesseqiddict[peptide] = sseqidlist\n",
    "            Homoblastp_parsDict[proteinid] = peptidesseqiddict\n",
    "    #print(Homoblastp_parsDict)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec25b4e3-6e3f-4b31-8567-4b5b42df6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Homoblastp_parsDict[\"Q96A99\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300eaed-b695-4c94-8adf-543b1a94d99c",
   "metadata": {},
   "source": [
    "## Step3: Parser the enzymedigest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cac6839-b048-48c8-b400-250efe4dfd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "## Parser the enzymedigest file\n",
    "##适用于TAA的分析\n",
    "EnzDigeDict={}\n",
    "with open(enzymedigest,\"r\") as enzymef:\n",
    "    for line in enzymef.readlines():\n",
    "        print(line)\n",
    "        if (''',\"[''' in line) and (''']\"''' in line):\n",
    "            #print(line)\n",
    "            refseq = re.split(',\"\\[',line)[0].split(\",\")[-1]\n",
    "            #print(refseq)\n",
    "            refid = line.split(\",\")[0].split(\"_\")[0].replace(\".\",\"_\").replace(\"|\",\"_\").replace(\">\",\"\")\n",
    "            seqlist = re.split(',\"\\[',line)[1].strip().replace(']\"','').replace(\"'\",\"\").split(\",\")\n",
    "        elif (''',[''' in line) and (''']''' in line):\n",
    "            #print(line)\n",
    "            refseq = re.split(',\\[',line)[0].split(\",\")[-1]\n",
    "            print(refseq)\n",
    "            refid = line.split(\",\")[0].split(\"_\")[0].replace(\".\",\"_\").replace(\"|\",\"_\").replace(\">\",\"\")\n",
    "            seqlist = re.split(',\\[',line)[1].strip().replace(']\"','').replace(\"'\",\"\").split(\",\")\n",
    "        EnzDigeDict[refid]=seqlist\n",
    "print(EnzDigeDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040d2680-3aa3-4c0a-95fa-f737ff0506ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB_1595COL10A1_MHCI_HLA-B*15:07.netMHC.csv\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "PB_151_COPA_MHCI_HLA-B*15:07.netMHC.csv\n",
      "SB\n",
      "WB\n",
      "PB_151_COPA_MHCI_HLA-C*03:03.netMHC.csv\n",
      "PB_1595COL10A1_MHCI_HLA-C*03:03.netMHC.csv\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "PB_151_COPA_MHCI_HLA-B*67:01.netMHC.csv\n",
      "WB\n",
      "PB_151_COPA_MHCI_HLA-C*07:02.netMHC.csv\n",
      "WB\n",
      "PB_151_COPA_MHCI_HLA-A*24:02.netMHC.csv\n",
      "PB_1595COL10A1_MHCI_HLA-B*67:01.netMHC.csv\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "PB_151_COPA_MHCI_HLA-A*02:01.netMHC.csv\n",
      "PB_1595COL10A1_MHCI_HLA-C*07:02.netMHC.csv\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "PB_1595COL10A1_MHCI_HLA-A*02:01.netMHC.csv\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "PB_1595COL10A1_MHCI_HLA-A*24:02.netMHC.csv\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "SB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n",
      "WB\n"
     ]
    }
   ],
   "source": [
    "## Parser the netMHC.csv\n",
    "mergeoutfile =  open(outpath+\"/MHCI_Epitopeonly_SB_WB.csv\",\"w\")\n",
    "filenum = 0\n",
    "for file in glob.glob(path_mhcI + \"/*.netMHC.csv\"):\n",
    "    filenum +=1\n",
    "    filename= os.path.basename(file)\n",
    "    print(filename)\n",
    "    outfile = open(outpath1+\"/\"+filename,\"w\")\n",
    "    with open(file,\"r\") as eptf:\n",
    "        for line in eptf.readlines():\n",
    "            itemlist = line.rstrip().split(\",\")\n",
    "            \"\"\"\n",
    "            itemlist is the line content of netMHC result\n",
    "            \"\"\"\n",
    "            if line.startswith(\"Pos\"):\n",
    "                appendlist = [\"TransMemb\",\"InCutmerRate\",\"InCutmerRegion\",\"HomoExsit\",\"HomoId\"]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                if filenum == 1:\n",
    "                    mergeoutfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "            else:\n",
    "                pos1 = int(itemlist[0])-1\n",
    "                peptide = itemlist[2]\n",
    "                pos2 = pos1 + len(peptide)\n",
    "                midpos = int((pos1+pos2)/2)\n",
    "\n",
    "                seqid =  \"_\".join(itemlist[10].split(\"_\")[0:3]) \n",
    "                '''\n",
    "                if itemlist[10][-1] != '_':\n",
    "                    seqid =  \"_\".join(itemlist[10].split(\"_\")[0:3]) \n",
    "                else:\n",
    "                    seqid = itemlist[10][:len(itemlist[10])-1]\n",
    "                '''\n",
    "                \n",
    "                #print(seqid,midpos)\n",
    "                ## get Transmembrane info\n",
    "                TM_f = TM_parsDict[seqid][midpos]\n",
    "                TM_flag = flagDict[TM_f]\n",
    "                \n",
    "                ## get enzymedigest info\n",
    "                Cut_flag = \"_\"\n",
    "                Cut_seq = \"_\"\n",
    "                '''\n",
    "                size0 = 0\n",
    "                overseq0 = \"\"\n",
    "                for seq in EnzDigeDict[seqid]:\n",
    "                    size,overseq = get_overlap(peptide,seq)\n",
    "                    if size > size0:\n",
    "                        size0 = size\n",
    "                        overseq0 = overseq\n",
    "                Cut_flag = '\"'+str(size0)+\"//\"+str(len(peptide))+'\"'\n",
    "                Cut_seq = overseq0\n",
    "                '''\n",
    "                \n",
    "                ## get homolgous info\n",
    "                if (homobed_or_blasp == \"homobed\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_bed(Homo_parsDict,seqid,pos1,pos2)\n",
    "                elif (homobed_or_blasp == \"homoblastp\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_blastp(Homoblastp_parsDict,seqid,peptide)\n",
    "                ##  output the results with filtering the \"SB\" lines\n",
    "                if (itemlist[-1] == \"SB\") or (itemlist[-1] == \"WB\"):\n",
    "                    print(itemlist[-1])\n",
    "                    appendlist = [TM_flag,Cut_flag,Cut_seq,HomoEx,Homo_flag]\n",
    "                    mergeoutfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                else:\n",
    "                    appendlist = [\"\",TM_flag,Cut_flag,HomoEx,Homo_flag]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a9d9a9b-65b7-401c-8988-3ab3a31decbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB_151_COPA_MHCII_DRB5_0202.netMHC.csv\n",
      "PB_1595COL10A1_MHCII_DRB4_0103.netMHC.csv\n",
      "PB_1595COL10A1_MHCII_DRB5_0202.netMHC.csv\n",
      "PB_151_COPA_MHCII_DRB4_0103.netMHC.csv\n",
      "PB_151_COPA_MHCII_DRB1_0403.netMHC.csv\n",
      "PB_1595COL10A1_MHCII_DRB1_0403.netMHC.csv\n",
      "PB_1595COL10A1_MHCII_DRB1_1602.netMHC.csv\n",
      "PB_151_COPA_MHCII_DRB1_1602.netMHC.csv\n"
     ]
    }
   ],
   "source": [
    "## Parser the netMHC.csv\n",
    "mergeoutfile2 =  open(outpath+\"/MHCII_Epitope_only_SB_WB.csv\",\"w\")\n",
    "filenum = 0\n",
    "for file in glob.glob(path_mhcII + \"/*.netMHC.csv\"):\n",
    "    filenum += 1\n",
    "    filename= os.path.basename(file)\n",
    "    print(filename)\n",
    "    outfile = open(outpath2+\"/\"+filename,\"w\")\n",
    "    with open(file,\"r\") as eptf:\n",
    "        for line in eptf.readlines():\n",
    "            itemlist = line.rstrip().split(\",\")\n",
    "            if line.startswith(\"Pos\"):\n",
    "                appendlist = [\"TransMemb\",\"InCutmerRate\",\"InCutmerRegion\",\"HomoExsit\",\"HomoId\"]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                if filenum == 1:\n",
    "                    mergeoutfile2.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "            else:\n",
    "                pos1 = int(itemlist[0])-1\n",
    "                peptide = itemlist[2]\n",
    "                pos2 = pos1 + len(peptide)\n",
    "                midpos = int((pos1+pos2)/2)\n",
    "\n",
    "                seqid = \"_\".join(itemlist[6].split(\"_\")[0:3])\n",
    "                '''\n",
    "                if itemlist[6][-1] != '_':\n",
    "                    seqid = itemlist[6]  \n",
    "                else:\n",
    "                    seqid = itemlist[6][:len(itemlist[6])-1]\n",
    "                seqid = seqid.replace(\"|\",\"_\").replace(\".\",\"_\")\n",
    "                '''\n",
    "                \n",
    "                ## get Transmembrane info\n",
    "                TM_f = TM_parsDict[seqid][midpos]\n",
    "                TM_flag = flagDict[TM_f]\n",
    "                \n",
    "                ## get enzymedigest info\n",
    "                Cut_flag = \"_\"\n",
    "                '''\n",
    "                size0 = 0\n",
    "                overseq0 = \"\"\n",
    "                for seq in EnzDigeDict[seqid]:\n",
    "                    size,overseq = get_overlap(peptide,seq)\n",
    "                    if size > size0:\n",
    "                        size0 = size\n",
    "                        overseq0 = overseq\n",
    "                Cut_flag = '\"'+str(size0)+\"//\"+str(len(peptide))+'\"'\n",
    "                Cut_seq = overseq0\n",
    "                '''\n",
    "                ## get homolgous info\n",
    "                if (homobed_or_blasp == \"homobed\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_bed(Homo_parsDict,seqid,pos1,pos2)\n",
    "                elif (homobed_or_blasp == \"homoblastp\") or (homobed_or_blasp == \"bedblastp\"):\n",
    "                    HomoEx,Homo_flag = get_homodict_blastp(Homoblastp_parsDict,seqid,peptide)\n",
    "                        \n",
    "                ##  output the results with filtering the \"SB\" lines\n",
    "                if (itemlist[-1] == \"SB\") or (itemlist[-1] == \"WB\"):\n",
    "                    appendlist = [TM_flag,Cut_flag,Cut_seq,HomoEx,Homo_flag]\n",
    "                    mergeoutfile2.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "                else:\n",
    "                    appendlist = [\"\",TM_flag,HomoEx,Homo_flag]\n",
    "                outfile.write(\",\".join(itemlist+appendlist)+\"\\n\")\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e520088-1a63-48a7-a6c0-4371fbb25780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB_1595COL10A1\n",
      "HLA-B*15:07\n",
      "HLA-C*03:03\n",
      "HLA-B*67:01\n",
      "HLA-C*07:02\n",
      "HLA-A*02:01\n",
      "PB_151_COPA\n",
      "HLA-B*15:07\n",
      "HLA-B*67:01\n",
      "HLA-C*07:02\n"
     ]
    }
   ],
   "source": [
    "df_SB_WB = pd.read_csv(outpath+\"/MHCI_Epitopeonly_SB_WB.csv\")\n",
    "proteinlist = list(df_SB_WB[\"Identity\"].unique())\n",
    "for seqid in proteinlist:\n",
    "    print(seqid)\n",
    "    try:\n",
    "        os.mkdir(outpath+\"/\"+seqid)\n",
    "    except:\n",
    "        pass\n",
    "    seqid_df = df_SB_WB[df_SB_WB[\"Identity\"].str.contains(seqid)]\n",
    "    MHClist= (seqid_df[\"MHC\"].unique())\n",
    "    for MHCid in MHClist:\n",
    "        print(MHCid)\n",
    "        seqid_mhcid_df = seqid_df[seqid_df[\"MHC\"].str.contains(MHCid,regex=False)]\n",
    "        seqid_mhcid_df.to_csv(outpath+\"/\"+seqid+\"/\"+seqid+\"_MHCI_\"+MHCid+\".netMHC.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8956f58-c225-42ee-9b0a-f01798667bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SB_WB = pd.read_csv(outpath+\"/MHCII_Epitope_only_SB_WB.csv\")\n",
    "proteinlist = list(df_SB_WB[\"Identity\"].unique())\n",
    "for seqid in proteinlist:\n",
    "    seqid2 = seqid.replace(\"|\",\"_\").replace(\".\",\"_\")\n",
    "    try:\n",
    "        os.mkdir(outpath+\"/\"+seqid2)\n",
    "    except:\n",
    "        pass\n",
    "    seqid_df = df_SB_WB[df_SB_WB[\"Identity\"].str.contains(seqid)]\n",
    "    MHClist= (seqid_df[\"MHC\"].unique())\n",
    "    for MHCid in MHClist:\n",
    "        seqid_mhcid_df = seqid_df[seqid_df[\"MHC\"].str.contains(MHCid)]\n",
    "        seqid_mhcid_df.to_csv(outpath+\"/\"+seqid2+\"/\"+seqid2+\"_MHCII_\"+MHCid+\".netMHC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9ded1-7269-42e7-8ae6-810b4585ede2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
